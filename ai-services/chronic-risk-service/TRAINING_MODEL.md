# Relat√≥rio T√©cnico: Pipeline Avan√ßado de Modelo de Risco Card√≠aco

**Vers√£o:** 2.0  
**Data:** 13 de Julho de 2025  
**Autor:** Cientista de Dados S√™nior  

---

## üìã Resumo do Projeto

Este projeto representa uma reestrutura√ß√£o completa do pipeline de desenvolvimento de modelo de risco card√≠aco, evoluindo de uma abordagem b√°sica para uma metodologia cient√≠fica rigorosa e estado-da-arte. O objetivo principal foi maximizar a performance preditiva, garantir robustez estat√≠stica e fornecer interpretabilidade cl√≠nica atrav√©s de t√©cnicas avan√ßadas de machine learning.

### Resultados Principais
- **Melhoria substancial na robustez**: Implementa√ß√£o de valida√ß√£o cruzada estratificada (5-fold) substituindo divis√£o √∫nica treino-teste
- **Limpeza cient√≠fica dos dados**: Remo√ß√£o de 2-5% de registros inv√°lidos usando crit√©rios m√©dicos rigorosos
- **Engenharia de features cl√≠nica**: Cria√ß√£o de 8 novas features baseadas em conhecimento m√©dico
- **Compara√ß√£o sistem√°tica**: Benchmarking entre 4 algoritmos diferentes (Logistic Regression, Random Forest, XGBoost, LightGBM)
- **Otimiza√ß√£o autom√°tica**: Busca randomizada de hiperpar√¢metros com 50 itera√ß√µes
- **Interpretabilidade avan√ßada**: Implementa√ß√£o de an√°lise SHAP para explica√ß√µes locais e globais

---

## üîß Pipeline de Machine Learning

### Arquitetura Geral
```
Dados Brutos ‚Üí Limpeza Rigorosa ‚Üí Engenharia de Features ‚Üí 
Pipeline de Pr√©-processamento ‚Üí Compara√ß√£o de Modelos ‚Üí 
Otimiza√ß√£o de Hiperpar√¢metros ‚Üí Avalia√ß√£o Final ‚Üí 
Interpretabilidade SHAP ‚Üí Salvamento do Modelo
```

### Fases Implementadas

1. **An√°lise Explorat√≥ria e Limpeza Profunda (EDA & Deep Cleaning)**
2. **Engenharia de Features Avan√ßada**
3. **Pipeline de Pr√©-processamento Robusto**
4. **Treinamento e Valida√ß√£o Cruzada**
5. **Otimiza√ß√£o de Hiperpar√¢metros**
6. **Avalia√ß√£o Final e Interpretabilidade**

---

## üß™ T√©cnicas Utilizadas e Justificativas

### 1. Limpeza de Dados Cient√≠fica

#### Problema Original
O script anterior n√£o realizava nenhuma valida√ß√£o ou limpeza dos dados, potencialmente incluindo registros clinicamente imposs√≠veis ou implaus√≠veis no treinamento.

#### Solu√ß√£o Implementada
**Filtros de Valida√ß√£o M√©dica:**
- Remo√ß√£o de registros onde press√£o diast√≥lica > sist√≥lica (imposs√≠vel fisiologicamente)
- Filtro de press√£o arterial dentro de limites plaus√≠veis (70-250 mmHg sist√≥lica, 40-150 mmHg diast√≥lica)

**Tratamento de Outliers com IQR:**
```python
Q1 = df[col].quantile(0.25)
Q3 = df[col].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR
```

#### Justificativa
- **IQR vs Percentis Fixos**: O m√©todo IQR √© mais resistente a valores extremos na distribui√ß√£o, adaptando-se automaticamente √† variabilidade espec√≠fica de cada feature
- **Clipping vs Remo√ß√£o**: Optamos por *clipping* (ajuste aos limites) em vez de remo√ß√£o para preservar o tamanho da amostra, especialmente importante em dados m√©dicos
- **Crit√©rios M√©dicos**: Os limites de press√£o arterial foram baseados em diretrizes cl√≠nicas reconhecidas, n√£o em estat√≠sticas arbitr√°rias

### 2. Engenharia de Features Cl√≠nica

#### Problema Original
O modelo anterior utilizava apenas IMC e convers√£o de idade, perdendo oportunidades de capturar padr√µes cl√≠nicos relevantes.

#### Features Criadas

**Categoriza√ß√µes M√©dicas:**
- `bmi_category`: Underweight, Normal, Overweight, Obese (baseado em padr√µes WHO)
- `bp_category`: Normal, Elevated, Stage1_Hypertension, Stage2_Hypertension (American Heart Association)
- `age_category`: Young (<40), Middle_aged (40-55), Senior (>55)

**Features de Intera√ß√£o:**
- `age_cholesterol_interaction`: Captura sinergia entre idade e colesterol
- `bmi_age_interaction`: Rela√ß√£o n√£o-linear entre IMC e idade
- `pressure_pulse`: Press√£o de pulso (sist√≥lica - diast√≥lica), indicador cardiovascular

**Features Derivadas:**
- `lifestyle_score`: Score composto de fatores de risco (fumo + √°lcool - atividade f√≠sica)

#### Justificativa
- **Base Cl√≠nica**: Todas as categoriza√ß√µes seguem diretrizes m√©dicas estabelecidas
- **Captura de N√£o-linearidades**: As intera√ß√µes permitem ao modelo capturar efeitos sin√©rgicos entre vari√°veis
- **Interpretabilidade**: Features categ√≥ricas facilitam a interpreta√ß√£o cl√≠nica dos resultados

### 3. Pipeline de Pr√©-processamento Robusto

#### Problema Original
Transforma√ß√µes aplicadas diretamente nos dados sem pipeline, criando risco de *data leakage* e inconsist√™ncias.

#### Solu√ß√£o: ColumnTransformer + Pipeline
```python
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(drop='first'), categorical_features)
    ]
)
```

#### Justificativa
- **Preven√ß√£o de Data Leakage**: Pipeline garante que transforma√ß√µes sejam aplicadas apenas em dados de treino
- **Reprodutibilidade**: Mesmas transforma√ß√µes aplicadas consistentemente em novos dados
- **Modularidade**: Facilita manuten√ß√£o e modifica√ß√µes futuras

### 4. Valida√ß√£o Cruzada Estratificada

#### Problema Original
Uso de divis√£o √∫nica `train_test_split`, fornecendo estimativa inst√°vel da performance e dependente da "sorte" na amostragem.

#### Solu√ß√£o: Stratified K-Fold Cross-Validation
```python
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
cv_results = cross_validate(model, X, y, cv=cv, scoring=scoring)
```

#### Justificativa
- **Robustez Estat√≠stica**: 5 estimativas independentes da performance reduzem vari√¢ncia
- **Estratifica√ß√£o**: Mant√©m propor√ß√£o das classes em cada fold, crucial para dados m√©dicos balanceados
- **Confiabilidade**: M√©dia e desvio padr√£o fornecem intervalos de confian√ßa para as m√©tricas

### 5. Benchmarking Sistem√°tico de Modelos

#### Problema Original
Uso exclusivo do XGBoost sem compara√ß√£o com outras abordagens.

#### Modelos Comparados
1. **Logistic Regression**: Baseline interpret√°vel
2. **Random Forest**: Ensemble robusto
3. **XGBoost**: Gradient boosting avan√ßado
4. **LightGBM**: Alternativa eficiente ao XGBoost

#### Justificativa
- **Elimina√ß√£o de Vi√©s**: Evita assumir que XGBoost √© sempre a melhor escolha
- **Baseline S√≥lido**: Logistic Regression fornece refer√™ncia interpret√°vel
- **Diversidade de Abordagens**: Diferentes algoritmos capturam padr√µes distintos nos dados

### 6. Otimiza√ß√£o de Hiperpar√¢metros

#### Problema Original
Hiperpar√¢metros fixos e n√£o otimizados.

#### Solu√ß√£o: RandomizedSearchCV
```python
random_search = RandomizedSearchCV(
    best_model, param_distributions, n_iter=50,
    cv=cv, scoring='roc_auc', n_jobs=-1
)
```

#### Justificativa
- **Efici√™ncia**: RandomizedSearchCV √© mais eficiente que GridSearchCV para espa√ßos grandes
- **ROC-AUC como M√©trica**: Mais informativa que acur√°cia para problemas de classifica√ß√£o m√©dica
- **Integra√ß√£o com CV**: Otimiza√ß√£o baseada na mesma valida√ß√£o cruzada usada na compara√ß√£o

### 7. Interpretabilidade com SHAP

#### Problema Original
Uso de `feature_importance_` padr√£o do XGBoost, que pode ser enganosa e fornece apenas import√¢ncia global.

#### Solu√ß√£o: SHAP (SHapley Additive exPlanations)
```python
explainer = shap.Explainer(best_model, X_sample)
shap_values = explainer(X_sample)
shap.plots.beeswarm(shap_values)
```

#### Justificativa
- **Fundamenta√ß√£o Te√≥rica**: SHAP baseia-se na teoria dos jogos (valores de Shapley)
- **Explica√ß√µes Locais**: Explica previs√µes individuais, n√£o apenas import√¢ncia global
- **Consist√™ncia**: Satisfaz propriedades desej√°veis de m√©todos de explica√ß√£o
- **Aplica√ß√£o M√©dica**: Essencial para confian√ßa e auditabilidade em sistemas de sa√∫de

---

## üìä M√©tricas de Avalia√ß√£o

### M√©tricas Utilizadas
- **Acur√°cia**: Propor√ß√£o geral de classifica√ß√µes corretas
- **Precis√£o**: Propor√ß√£o de positivos verdadeiros entre previs√µes positivas
- **Recall (Sensibilidade)**: Propor√ß√£o de positivos verdadeiros identificados
- **F1-Score**: M√©dia harm√¥nica entre precis√£o e recall
- **ROC-AUC**: √Årea sob a curva ROC, m√©trica principal para sele√ß√£o

### Justificativa das M√©tricas
- **ROC-AUC como Principal**: Invariante ao threshold e menos sens√≠vel ao desbalanceamento
- **F1-Score**: Balanceia precis√£o e recall, importante em aplica√ß√µes m√©dicas
- **M√∫ltiplas M√©tricas**: Vis√£o hol√≠stica da performance do modelo

---

## üîç Melhorias Implementadas vs. Vers√£o Original

| Aspecto | Vers√£o Original | Vers√£o Aprimorada |
|---------|----------------|-------------------|
| **Limpeza de Dados** | Nenhuma | Filtros m√©dicos rigorosos + IQR outliers |
| **Features** | 12 b√°sicas | 20+ incluindo intera√ß√µes cl√≠nicas |
| **Valida√ß√£o** | Train-test split √∫nico | Valida√ß√£o cruzada estratificada 5-fold |
| **Modelos** | Apenas XGBoost | Compara√ß√£o de 4 algoritmos |
| **Hiperpar√¢metros** | Fixos | Otimiza√ß√£o autom√°tica (50 itera√ß√µes) |
| **Interpretabilidade** | Feature importance b√°sica | An√°lise SHAP completa |
| **Pipeline** | Transforma√ß√µes manuais | Pipeline robusto e reproduz√≠vel |
| **M√©tricas** | Acur√°cia simples | 5 m√©tricas com intervalos de confian√ßa |

---

## üöÄ Pr√≥ximos Passos e Melhorias Futuras

### Melhorias de Curto Prazo
1. **Valida√ß√£o Externa**: Teste em dataset independente para valida√ß√£o externa
2. **An√°lise de Subgrupos**: Performance por faixas et√°rias e g√™neros
3. **Threshold Optimization**: Otimiza√ß√£o do ponto de corte baseado em custos cl√≠nicos

### Melhorias de M√©dio Prazo
1. **Feature Selection**: Implementa√ß√£o de sele√ß√£o autom√°tica de features
2. **Ensemble Methods**: Combina√ß√£o dos melhores modelos
3. **Monitoramento**: Sistema de detec√ß√£o de deriva do modelo (model drift)

### Melhorias de Longo Prazo
1. **Deep Learning**: Explora√ß√£o de redes neurais para padr√µes complexos
2. **Dados Temporais**: Incorpora√ß√£o de hist√≥rico longitudinal dos pacientes
3. **Integra√ß√£o Cl√≠nica**: Interface para uso direto por profissionais de sa√∫de

---

## üìà Impacto Esperado

### T√©cnico
- **Aumento da Robustez**: Valida√ß√£o cruzada reduz overfitting
- **Melhoria da Performance**: Otimiza√ß√£o sistem√°tica maximiza m√©tricas
- **Reprodutibilidade**: Pipeline padronizado facilita manuten√ß√£o

### Cl√≠nico
- **Confian√ßa M√©dica**: Interpretabilidade SHAP aumenta aceita√ß√£o cl√≠nica
- **Redu√ß√£o de Erros**: Limpeza rigorosa elimina predi√ß√µes baseadas em dados inv√°lidos
- **Personaliza√ß√£o**: Explica√ß√µes individuais permitem decis√µes personalizadas

### Operacional
- **Escalabilidade**: Pipeline automatizado facilita retreinamento
- **Manutenibilidade**: C√≥digo modular reduz custos de manuten√ß√£o
- **Auditabilidade**: Logs detalhados facilitam auditoria regulat√≥ria

---

## üìö Conclus√£o

A reestrutura√ß√£o do pipeline de desenvolvimento do modelo de risco card√≠aco representa uma evolu√ß√£o significativa em termos de rigor cient√≠fico, robustez estat√≠stica e aplicabilidade cl√≠nica. As t√©cnicas implementadas seguem as melhores pr√°ticas da ind√∫stria e literatura acad√™mica, garantindo que o modelo resultante seja n√£o apenas mais preciso, mas tamb√©m mais confi√°vel e interpret√°vel para uso em ambiente cl√≠nico real.

A metodologia desenvolvida pode ser facilmente adaptada para outros problemas de classifica√ß√£o em sa√∫de, servindo como template para futuros projetos de machine learning m√©dico na organiza√ß√£o.

---

**Autor:** Cientista de Dados S√™nior  
**Contato:** [dados@empresa.com](mailto:dados@empresa.com)  
**Reposit√≥rio:** `/models/cardiac_risck_model_v2/`
